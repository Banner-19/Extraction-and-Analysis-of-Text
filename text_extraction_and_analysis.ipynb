{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries\n",
    "- pandas: Used for data manipulation and handling Excel files.\n",
    "- BeautifulSoup: A library for parsing HTML and XML documents, used for web scraping.\n",
    "- requests: Used to send HTTP requests to the website and get the HTML content.\n",
    "- TextBlob: A library for processing textual data, used for sentiment analysis.\n",
    "- nltk: Natural Language Toolkit, used for tokenization and stop words.\n",
    "- stopwords: A list of common stop words.\n",
    "- word_tokenize and sent_tokenize: Functions for tokenizing text into words and sentences, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download NLTK resources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Bhaskar\n",
      "[nltk_data]     Banerjee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Bhaskar\n",
      "[nltk_data]     Banerjee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read input Excel file\n",
    "- This section reads the input Excel file (Input.xlsx) containing the URLs and other input data. It also specifies the output file name (Output Data Structure.xlsx) where the computed variables will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"Input.xlsx - Sheet1.csv\"\n",
    "output_file = \"Output Data Main.xlsx\"\n",
    "\n",
    "input_df = pd.read_csv(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize lists to store output data\n",
    "- This dictionary output_data is initialized to store the computed variables along with input variables. Each key represents a variable name, and the corresponding value is an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = {\n",
    "    \"URL_ID\": [],\n",
    "    \"URL\": [],\n",
    "    \"ARTICLE_TITLE\": [],\n",
    "    \"ARTICLE_TEXT\": [],\n",
    "    \"POSITIVE_SCORE\": [],\n",
    "    \"NEGATIVE_SCORE\": [],\n",
    "    \"POLARITY_SCORE\": [],\n",
    "    \"SUBJECTIVITY_SCORE\": [],\n",
    "    \"AVG_SENTENCE_LENGTH\": [],\n",
    "    \"PERCENTAGE_OF_COMPLEX_WORDS\": [],\n",
    "    \"FOG_INDEX\": [],\n",
    "    \"AVG_NUMBER_OF_WORDS_PER_SENTENCE\": [],\n",
    "    \"COMPLEX_WORD_COUNT\": [],\n",
    "    \"WORD_COUNT\": [],\n",
    "    \"SYLLABLE_PER_WORD\": [],\n",
    "    \"PERSONAL_PRONOUNS\": [],\n",
    "    \"AVG_WORD_LENGTH\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to extract text from URL\n",
    "- extract_text_from_url: This function takes a URL as input, extracts the article title and text from the webpage using BeautifulSoup, and returns them.\n",
    "- syllable_count: This function calculates the number of syllables in a word, used in computing syllables per word.\n",
    "- analyze_text: This function performs text analysis on the given text using TextBlob and returns various computed variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Find article title\n",
    "    article_title = soup.find('title').text.strip()\n",
    "    \n",
    "    # Find article text\n",
    "    article_text = \"\"\n",
    "    for paragraph in soup.find_all('p'):\n",
    "        article_text += paragraph.text.strip() + \"\\n\"\n",
    "    \n",
    "    return article_title, article_text\n",
    "\n",
    "# Function to calculate syllables in a word\n",
    "def syllable_count(word):\n",
    "    word = word.lower()\n",
    "    count = 0\n",
    "    vowels = 'aeiouy'\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "    if word.endswith('e'):\n",
    "        count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "# Function to compute text analysis\n",
    "def analyze_text(text):\n",
    "    blob = TextBlob(text)\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    positive_score = sum(1 for word in blob.words if TextBlob(word).sentiment.polarity > 0)\n",
    "    negative_score = sum(1 for word in blob.words if TextBlob(word).sentiment.polarity < 0)\n",
    "    polarity_score = blob.sentiment.polarity\n",
    "    subjectivity_score = blob.sentiment.subjectivity\n",
    "    avg_sentence_length = sum(len(sent.split()) for sent in sentences) / len(sentences)\n",
    "    complex_words = [word for word in words if syllable_count(word) > 2 and word.lower() not in stop_words]\n",
    "    percentage_complex_words = (len(complex_words) / len(words)) * 100 if len(words) > 0 else 0\n",
    "    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
    "    avg_words_per_sentence = len(words) / len(sentences)\n",
    "    complex_word_count = len(complex_words)\n",
    "    word_count = len(words)\n",
    "    syllables = sum(syllable_count(word) for word in words)\n",
    "    syllable_per_word = syllables / word_count if word_count > 0 else 0\n",
    "    personal_pronouns = sum(1 for word in words if word.lower() in ['i', 'me', 'my', 'mine', 'myself', 'we', 'us', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves'])\n",
    "    avg_word_length = sum(len(word) for word in words) / len(words) if len(words) > 0 else 0\n",
    "    \n",
    "    return (positive_score, negative_score, polarity_score, subjectivity_score, \n",
    "            avg_sentence_length, percentage_complex_words, fog_index, avg_words_per_sentence, \n",
    "            complex_word_count, word_count, syllable_per_word, personal_pronouns, avg_word_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Processing Loop\n",
    "- This loop iterates over each row in the input Excel file. For each URL, it extracts the article text, performs text analysis, and stores the computed variables along with input variables in the output_data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in input_df.iterrows():\n",
    "    url_id = row['URL_ID']\n",
    "    url = row['URL']\n",
    "    \n",
    "    # Extract text from URL\n",
    "    article_title, article_text = extract_text_from_url(url)\n",
    "    \n",
    "    # Perform text analysis\n",
    "    (positive_score, negative_score, polarity_score, subjectivity_score, avg_sentence_length, \n",
    "     percentage_complex_words, fog_index, avg_words_per_sentence, complex_word_count, word_count, \n",
    "     syllable_per_word, personal_pronouns, avg_word_length) = analyze_text(article_text)\n",
    "    \n",
    "    # Store data in output dictionary\n",
    "    output_data[\"URL_ID\"].append(url_id)\n",
    "    output_data[\"URL\"].append(url)\n",
    "    output_data[\"ARTICLE_TITLE\"].append(article_title)\n",
    "    output_data[\"ARTICLE_TEXT\"].append(article_text)\n",
    "    output_data[\"POSITIVE_SCORE\"].append(positive_score)\n",
    "    output_data[\"NEGATIVE_SCORE\"].append(negative_score)\n",
    "    output_data[\"POLARITY_SCORE\"].append(polarity_score)\n",
    "    output_data[\"SUBJECTIVITY_SCORE\"].append(subjectivity_score)\n",
    "    output_data[\"AVG_SENTENCE_LENGTH\"].append(avg_sentence_length)\n",
    "    output_data[\"PERCENTAGE_OF_COMPLEX_WORDS\"].append(percentage_complex_words)\n",
    "    output_data[\"FOG_INDEX\"].append(fog_index)\n",
    "    output_data[\"AVG_NUMBER_OF_WORDS_PER_SENTENCE\"].append(avg_words_per_sentence)\n",
    "    output_data[\"COMPLEX_WORD_COUNT\"].append(complex_word_count)\n",
    "    output_data[\"WORD_COUNT\"].append(word_count)\n",
    "    output_data[\"SYLLABLE_PER_WORD\"].append(syllable_per_word)\n",
    "    output_data[\"PERSONAL_PRONOUNS\"].append(personal_pronouns)\n",
    "    output_data[\"AVG_WORD_LENGTH\"].append(avg_word_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Output to Excel\n",
    "- Finally, the computed data is converted to a pandas DataFrame (output_df) and written to the output Excel file specified earlier (Output Data Structure.xlsx), without including the index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame(output_data)\n",
    "output_df.to_excel(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
